<<<<<<< Updated upstream
[["04-data.html", "4 Data Wrangling 4.1 Intro to Spatial Data 4.2 Projections 4.3 Convert CSV to GeoJSON 4.4 Geocode Addresses 4.5 Clean Data (Long to Wide Format) 4.6 Merge Datasets 4.7 Inspect Data as Choropleth Map 4.8 Overlay Points and Boundary Data 4.9 Add a Spatial Join 4.10 stuff", " 4 Data Wrangling Objectives In this module, you will: Expand your understanding of the social determinants of health and equity Learn how spatial data visualizations are used in public health Define four main types of web mapping applications By the end, you should have an idea of which type of spatial data visualization type you plan to work with for your project. 4.1 Intro to Spatial Data 4.2 Projections The Earth is an irregular ellipsoid, rather than a perfect sphere. As a result, many ways of visualizing the Earth, in whole or in part, have been developed. A Coordinate Reference System (CRS) communicates what method should be used to flatten or project the Earth’s surface onto a 2-dimensional map. Different CRS imply different ways of projections and can generate substantially different visualizations. For example, the following are some world maps using different projections: pic from slide 13 intro2spatialmed In addition to projections that optimize for global accuracy, there are many regional projections. For instance, NAD83 (North American Datum 1983) is divided into several UTM (universal transverse mercator) zones across the continent. So when projecting a dataset of Illinois, for example, the most appropriate NAD83 projection would be NAD83 UTM zone 16N. Projection names have also been standardized to EPSG codes. The projection NAD83 UTM zone 16N is EPSG:26916. Many datasets available online, and GeoJSON files as a general rule, default to the projection EPSG:4326, a global projection used by GPS. Changing projections can be critical for improving accuracy for your project, and making sure your layers are being displayed using the same information. Always search the internet to determine what projection is most appropriate for your project, and to find the corresponding EPSG code. For this exercise we’ll use QGIS to change the projection of a spatial dataset. Note: Mac users will need to override a security setting to download QGIS. Once you have installed QGIS, you will need to go to Security and Privacy in System Preferences. There, you will find a message that “1 GADL Complete.pkg” was unable to be opened. Select “Open Anyway.” You may need to do this for multiple packages depending on the version of QGIS you download. If you still have issues opening QGIS after this, Stack Overflow is a great resource for troubleshooting GIS software issues. Once you have opened QGIS, open a new project. QGIS will default new projects to the projection EPSG 4326. Open the file boundaries_chicago.geojson as a new layer by navigating through the Browser on the left hand side of QGIS. Double click or drag and drop the file into Layers. Inspect the current projection. In the bottom right corner of QGIS, the projection for the project as a whole will be listed as the EPSG code. Select this to change the projection. Since we’re working with a Chicago dataset, let’s change the projection to EPSG:26916. screencap available: 1projection Notice how the shape of the city boundary changed, now that the projections are not in agreement. Inspect the projection for the boundary layer by right clicking on the layer and going to Layer CRS. The current projection should be EPSG:4326. Since the project is now in EPSG:26916, you should see the option Set to EPSG:26916. This may cause the layer to move enough that it is no longer visible on your screen. If this ever happens, use Zoom to Layer(s) to return to your layer. Now you can see the boundary shape has changed again with the projections being back in agreement. 4.3 Convert CSV to GeoJSON CSV files are not spatial data; they may contain spatial data, but to be used for mapping they will need to be converted to a spatial data format, such as a GeoJSON or shapefile. As long as a CSV contains spatial data, GIS software should allow you to save CSV data as a new spatial data file. Here, we’ll convert CSV files to GeoJSON files without code using GeoDa. For this type of conversion, you’ll want a CSV file with latitude and longitude information in separate fields. If you are starting with address information, see the section “Geocode Addresses.” Once you have installed GeoDa, select Open and open your CSV file. We’ll use Affordable_Rental_Housing_Developments.csv for this exercise. You will be prompted to indicate which fields in your CSV contain longitude and latitude. Select the appropriate fields, then hit OK. Note: use excel to split and reformat fields for files where latitude and longitude are in a single field. screencap available: 2csvtojson A map of your data will be generated. Within the map view, you can add a base map by selecting Base Map (second from right in the toolbar). To save your data in a spatial data format, go to File -&gt; Save As. When you select a file path, you will be prompted to select a file format. Select GeoJSON and the appropriate file path. Once you save, you should have a new GeoJSON file. screencap available: 3csvtojsonsave 4.4 Geocode Addresses Addresses are not spatial data. They are real-world representations of spatial data, but GIS software will not be able to map them without further information. Geocoding is the process of converting addresses into geographic coordinates using a known coordinate reference system (CRS). We can then use these coordinates (latitude, longitude) to spatially enable data. Here, we’ll turn addresses into spatial data points without coding using QGIS, an open source GIS software. To geocode addresses in QGIS, first you will need to install the plugin MMQGIS. Go to Plugins -&gt; Manage and Install Plugins. Search MMQGIS, and install it. screencap available: 4mmqgis Once installed, the plugin should be visible on the toolbar across the top. Select MMQGIS -&gt; Geocode -&gt; Geocode CSV with Web Service. screencap available: 5geocodepathway Upload your CSV file, for this exercise we’ll use chicago_methadone_nogeometry.csv. Confirm the correct fields are being read, choose your web service (OpenStreetMap is the open source option), and name your output files and select the file formats. Hit apply, and the addresses should appear as points, and a spatial data file should have been generated and appear on the left side of your screen as a new layer. screencap available: 6geocodeparameters Pitfall Not all my addresses geocoded! QGIS may be having an issue reading some specific addresses due to formatting issues in the CSV. Suite or apartment numbers, for example, may cause QGIS to be unable to geocode addresses. Only include the street address in the address column of your CSV. If you want to retain apartment or suite numbers, include them in a separate column in your CSV. An address may also be miswritten in your CSV file, even something as small as an extra apostrophe will prevent an address from being geocoded properly. Edit your CSV to be properly formatted, and upload it again. Note: you may need to close and reopen QGIS if you add columns to your CSV as part of this editing process. Once all your addresses are appearing, investigate them to ensure that everything has geocoded properly. For small datasets, this can be done by investigating the layer attribute table. Right click your geocoded layer and select Open Attribute Table. In addition to the information from your CSV, QGIS will have added a few more pieces of information, including the full address and lat/long. Take a look at this information to ensure everything has in fact appeared at the correct address. If you have a dataset confined to a single city, this can be done very quickly by checking the lat/long data for any outliers. However, this method is not suitable for larger datasets. For datasets of all sizes, adding a basemap will contextualize your data and allow for a quick visual inspection. To add a basemap, you’ll need to download a plugin. The simplest basemap system is a part of the QuickMapServices plugin. Go to Plugins -&gt; Manage and Install Plugins. Search QuickMapServices, and install it. Once installed, select Web -&gt; QuickMapServices. Depending on your version of QGIS you may have different base map options, but all versions should at least have OSM Standard. Select this to add the base map. Alternatively, the OpenLayer plugin will also provide base map options. screencap available: 7osmbasemappathway With a basemap now added, you can quickly visually inspect your data points. From the layers sidebar, right click your geocoded spatial data file and select Zoom to Layer(s). If any data points lie outside your expected spatial extent, this will quickly alert you to that issue. The point data may have defaulted to a style that is difficult to see against this base map. Right click your geocoded spatial data file and select Styles to edit the size, color, and shape of your data points. Pitfall An address geocoded incorrectly! Many cities have addresses that are duplicates or are very similar. Providing QGIS the most information you can is the best way to resolve this issue. QGIS can use street address, city, state, and country information to geocode addresses. If you do not already have all of this information in your original CSV, add it and try geocoding again. Once everything has geocoded properly, you’ll have a spatial data file ready to use in other software. 4.5 Clean Data (Long to Wide Format) Datasets often don’t come in GIS-friendly formats. Data may be separated vertically among multiple variables rather than horizontally along a single identifying variable. Open COVID-19_Cases__Tests__and_Deaths_by_ZIP_Code.csv in GeoDa, leaving the latitude and longitude options open since that information is not contained in this dataset. If a table does not automatically open, open it through the toolbar. You’ll notice zip codes repeat as they are separated by week, rather than weeks each being columns within one row for each zip code. This is considered a long data format, the latter being a wide data format. This data can be cleaned in a number of ways in GeoDa, but let’s try pulling just the last week of the dataset. Columns can be sorted from lowest to highest (or vice versa) by double clicking the column name. Double click the Week Number column until it displays highest to lowest to find the last week in the dataset. You can select this data through two ways: 1) click the first row you want, then shift+click the last row you want, which should select everything between the two rows, or 2) go to Table -&gt; Selection Tool, set Week Number as the Selection Variable, and set both the upper and lower bound of the range to 40 (the last week in the data set), then select Select All in Range. Once a selection is made and includes all the data you want, go to File -&gt; Save Selected As to save it as its own dataset. Further clean this new dataset by opening it in GeoDa, then choose Table -&gt; Delete Variable(s). Remove any variables that are not relevant to your study. For instance, we were only interested in cumulative case rates for this dataset, we would remove all variables except Zip Code and Cases - Cumulative. You can also change variable names if you want to specify the week in question. Excel can also be useful in this type of data cleaning. To create a wide dataset with the cumulative cases for each week for each zip code, create a pivot table in excel. Open the CSV as an excel file, and open a new sheet. In that new sheet, go to Insert -&gt; Pivot Table. Select the data you wish to include, in this case we want the cumulative case data. Choose the icon on the right of the Table/Range selection box, and select columns A-F from the original excel sheet. Make sure the pivot table will be placed in the new excel sheet, and hit OK. The pivot table will open with the selected data, which can be sorted into rows, columns, values, and filters. In this example, the zip codes should be our rows, so choose Zip Code from the selection and drag it into Rows. We want our columns to be organized by week, so drag any of the Week Number, Week Start, or Week End into the Columns. You’ll notice these variables split into multiple categories when dragged into a pivot table field. Use the information icon at the side of each category to hide the Months and Days, leaving you with just the original variable. Finally, drag Cases - Cumulative into the Values to fill out the table. Use the drop down menu for Row Labels or Column Labels to remove any unwanted rows or columns. You’ll notice a Grand Total for each column and row has also been created, which can be removed. Also remove the first row that includes Sum of Cases and Column Labels, and rename the column containing zip codes, from Row Labels to Zip Code. These extra columns and rows could make it difficult for other software to read your CSV later. Your completed pivot table (and its fields creator*) will look something like this: screencap available: 8pivotresult Save the sheet as a new CSV by going to File -&gt; Save As. 4.6 Merge Datasets Merging datasets is a vital skill for analyzing health data from an SDOH perspective. SDOH data and health data will often be in separate datasets, but use the same geographic scale, such as zip code or census tract. Being able to merge these kinds of datasets together using that scale is important to the ease of performing analysis with your data. Here, we’ll merge datasets with a common variable using GeoDa. Merging the cumulative case dataset you created in the last section to zip code spatial data will allow you to map the case data. First, open the Chicago zip code GeoJSON file in GeoDa. Open the table and identify the column name that contains zip code information. You’ll be merging the case data and spatial data using zip codes. First, however, you’ll notice that the zip codes are repeated. This is a quirk of the dataset, and this data needs to be cleaned before we can continue with merging the data. Select one row for each zip code and save the selection as a new geojson, ChiZipCleaned. You’ll notice that two zip codes (60643 and 60707) have repeats that are not exactly alike. This is because these two zip codes have small exclaves, and so are listed separately since they are separate polygons. However, having the repeated zip code will create problems when merging the data, and the exclaves are small enough not to be relevant for our analysis. Only choose the rows with a larger area for these two zip codes. Your selection should come to 58 zip codes. Open ChiZipCleaned.geojson. Go to Table -&gt; Merge. Select the cumulative case dataset. Under parameters, select Merge by key values, with zip selected for current table key and Zip Code selected for import table key. Move over all data columns you want to see in this merged dataset. Note: you do not need to include Zip Code since this field is being used to merge the two datasets, including it will only duplicate zip codes in the resulting dataset. screencap available: 9mergeparameters 4.7 Inspect Data as Choropleth Map Inspect data, both through spatial and non-spatial means, when starting a new project. This helps verify that all data wrangling to this point has occurred properly. To inspect data from a spatial perspective, create a series of choropleth maps. From the Map option on the toolbar, you can select a variety of choropleth map options using different variables or breaks for your data. Upon selecting a mapping option, you will be prompted to select a variable to map. Inspect your data by comparing how different data breaks present the same variables, and how the spatial patterns of different variables compare. Screencap available: 10choroplethmaps 4.8 Overlay Points and Boundary Data Overlay multiple datasets to investigate how they correspond to one another. Open the datasets you are interested in and order your layers appropriately to get an initial view of potential relationships between datasets. GeoDa: With the Chicago zip code data already loaded in GeoDa, add a layer of point data with Affordable_Rental_Housing_Developments.csv. From the map view, select Add Map Layer (third from left). Select the affordable housing dataset and set the lat/long fields so it will map properly, then hit OK. If you do not see the housing data, go to Map Layer Settings. Make sure the layer is turned on and ordered first, as it will not be visible below the zip code data layer. This point data set can be added to any map you create using the zip code data. Once you add it to one map, you should be able to find it as a layer in each subsequent map that can be turned on rather than reuploading every time. Note: the first row does not have lat/long data and may impede GeoDa from mapping the rest of the affordable housing dataset. If you have this problem, try removing this row from the CSV. Screencap available: 11overlaymap QGIS: Load Chicago zip code data in QGIS by adding ChiZipCleaned.geojson into a new project. Let’s overlay this boundary data with affordable housing point data. Since Affordable_Rental_Housing _Development.csv is not a spatial data file, it cannot be added directly from Browser in order to appear on the map. Instead, go to Layer -&gt; Add Layer-&gt; Delimited Text Layer. Navigate to the file, and ensure all fields indicate the correct data source in order to display the data properly. screencap available: 12qgisoverlay Adjust the color, transparency, size, and borders of each layer by right clicking the layer and going to Styles -&gt; Edit Symbol. The affordable housing data can also be saved as a spatial dataset at this point, by right clicking on the layer and navigating to Save Features As. 4.9 Add a Spatial Join Add spatial joins to data to analyze the relationships datasets may have with each other. This tool allows you to merge certain aspects of datasets, such as joining descriptive statistics about one datasets relation to the other. Continuing from the project we created in the previous section (affordable housing development data and ChiZipCleaned.geojson), we’ll create a spatial join, which means adding information about attributes of one dataset to the other. In this case, we’ll add the number of affordable housing developments in each zip code to the zip code dataset. Go to Processing -&gt; Toolbox and search for Join Attributes. For this exercise, select Join attributes by location (summary). Set the following parameters: screencap available: 13joinparameters These parameters are set on the premise that we want a count of the affordable housing developments contained within each zip code. A joined layer will be mapped on top of your current layers. Pitfall Invalid Geometries Zip code 60655 has an enclave not included in the Chicago city limits, and you may have a technical issue with that enclave when moving between GeoDa and QGIS with the newly cleaned Chicago zip code data that causes an Invalid Geometry error when conducting a spatial join. Since the zip code in question has no affiliated affordable housing developments, in this case we’ll set the Invalid feature filter, found under the layer’s Advanced Options when creating the spatial join, to skip features with invalid geometries. Change the symbology by right clicking and going to Properties -&gt; Symbology. Change the symbology from Single Symbol to Graduated with the value Community Area Name_count. Try changing the color ramp, mode, and number of classes. The resulting joined layer may look similar to the one below. screencap available: 14joinmap Note: In order for null values to appear, you may need to first set symbology to graduated colors, then change it to Rule-based. Add a field with the rule set to Else rather than Filter. Then change colors and arrange as you wish. 4.10 stuff testing - What is Spatial Data Inspection - viewing tables &amp; data itself Projections &amp; Coordinate Reference Systems CSV to Spatial Points Merging spatial data (area-level) Reshaping data Calc new spatial variables? [[ likely pare this down, move some to data assessment above, and some of the rest to later module? ]] After understanding the significance of refining objectives and finding stakeholders, it is crucial to take into account one of the essential elements in your project–the spatial component. This toolkit underscores the fact that social determinants of health encompass more than personal genetics or healthy habits. According to the World Health Organization, social determinants of health refer to the conditions in which people are born, grow, live, work, and age (https://health.gov/healthypeople, accessed 11 October, 2023 ). By adopting a spatial view of SDOH, we can research how communities are affected by the places they inhabit. For instance, we can evaluate their access to health care, transportation, recreation, and green areas. On the other hand, some communities may be exposed in their neighborhoods to crime, racism, and pollution. By mobilizing spatial visualizations, we can identify and address these inequalities. The spatial data we need for our visualizations can be quite different. While censuses and databases can provide a starting point, it’s important to understand their nature - what they include and what they leave out, who generates them (whether it’s the public or private sector), and what their intended purpose is. Scrutinizing spatial data is critical to start conceiving your spatial visualization. Think of spatial data as your high-powered lens zooming in on a community’s heartbeat. It lets you see beyond the surface to the underlying structures—like healthcare reach, parks, and transport. And yes, it also uncovers the shadows of crime, discrimination, and pollution. In your SDOH project, you can typically use three types of spatial data: primary, secondary, and tertiary. In the following section, we will provide a brief description of each of these types of data. Types of data, (graphic created by Kamaria Barronville based on Krygier and Wood, 2016) Primary Spatial Data: Primary spatial data refers to the data that you can collect either personally or through a sensor/machine which you or your stakeholders have previously installed. There are several examples of spatial visualizations of SDOH made with primary data. Some researchers have used online interviews or questionnaires to analyze their experiences in their neighborhood. Other researchers have placed sensors to map air quality in cities. The use of Global Positioning Systems (GPS) or smartphones is another way to generate primary data. Secondary Spatial Data: You may encounter challenges when gathering SDOH primary spatial data, as it can be a time-consuming and costly endeavor. As a result, SDOH researchers, mapmakers, and advocates frequently turn to various secondary resources, such as spatial databases and census records, to inform their spatial representations. Typically, these files consist of digital layers that are prepared for seamless incorporation into a GIS or web mapping application. However, you can also work and manipulate non-spatial data in your project. Notable sources for such data include both profit and non-profit databases, government census information, and even digitized or scanned paper maps. Tertiary Spatial Data: In the realm of SDOH spatial visualizations, there exists a third option–your map(s) may access other maps’ spatial data. Tertiary spatial data are spatial layers that have been previously or currently utilized in other cartographies and are readily accessible for integration into a Geographic Information System (GIS) or web mapping applications. When engaging with stakeholders experienced in health mapping, it’s worth inquiring whether they possess any spatial layers that could prove beneficial for your project. It is key to emphasize that data can often be tainted by biases and errors. As a result, the methods used to gather, aggregate, or model spatial data can have adverse effects on the quality of our data visualizations. It is of utmost importance to meticulously scrutinize various forms of data, whether they are qualitative (e..g, interviews or questionnaires), quantitative (e.g., databases), or mixed (e.g., surveys). A valuable starting point for data analysis involves assessing metadata within databases or interview questions. Further insights into this subject will be explored in subsequent sections of this toolkit. Project Tip: In your project, there’s no need to limit yourself to just one kind of data. In fact, it’s not only possible but often necessary to mix and match different sources and types of spatial data to craft compelling SDOH spatial visualizations. Activity 1.3: Review these projects below and identify what type of data they use. In your opinion, what other types of data could they use to enrich their visualizations? [Using Asset Mapping to Identify Health Needs of a Latinx Population in Rural Virginia] (https://scholarscompass.vcu.edu/cgi/viewcontent.cgi?article=1396&amp;context=uresposters) [US Social Determinants of Health Atlas - Map of the Month] (https://carto.com/blog/visualizing-health-data-social-factors) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
=======
[["o4r-data.html", "4 Data Wrangling in R 4.1 Intro to Spatial Data Concept 4.2 Environmental Setup 4.3 Convert CSV Lat/Long to Points 4.4 Prepare Spatial Data 4.5 Geocode Addresses to Points 4.6 Merge SDOH Data to Boundary Dataset 4.7 Graduated Symbology &amp; Choropleth Map", " 4 Data Wrangling in R Objectives In this module, you will: Introduction to spatial data concepts and operations Convert CSV lat/long to spatial points and geocode address Overlay points with boundary data, merge SDOH data, visualize as choropleth 4.1 Intro to Spatial Data Concept Spatial data is essential for understanding the world around us, as it combines information with specific locations. This type of data is vital because it allows us to see how information changes with location. Without the geographical component, we’re left with just a list, not a map that can guide decisions or provide insights. An important concept within spatial data is “simple features,” which is an international standard for how we represent real-world objects and their shapes on computers. This standard is the backbone of many Geographic Information Systems (GIS) technologies, making it easier for us to map and analyze spatial data. For example, in the R programming environment, spatial objects can be stored in a way that’s easy to work with, integrating seamlessly with other data analysis processes. Understanding these aspects of spatial data is crucial, especially as we delve into more complex analyses. Whether it’s navigating through the components of a shapefile or exploring data in R, having a grasp on these concepts can help tackle the challenges that come with spatial data analysis. 4.2 Environmental Setup Before starting operations related to spatial data, we need to complete an environmental setup. A basic understanding of R is assumed. This workshop requires several packages, which can be installed from CRAN: install.packages(&quot;sf&quot;, &quot;tmap&quot;, &quot;tidygeocoder&quot;, &quot;dplyr&quot;) For Mac users, check out https://github.com/r-spatial/sf for additional tips if you run into errors when installing the sf package. Using homebrew to install gdal usually fixes any remaining issues. Now, loading the libraries: library(sf) ## Linking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union 4.3 Convert CSV Lat/Long to Points Converting CSV latitude and longitude data to points in R is a straightforward yet powerful method for spatial analysis. This process involves using the sf package to transform geographic coordinates into spatial points, allowing for easy mapping and analysis. It’s an essential step for anyone working with geospatial data, enabling the visualization of locations and the application of geographic information systems (GIS) techniques. By assigning a Coordinate Reference System (CRS), these points become ready for spatial operations. We are using the “Affordable_Rental_Housing_Developments.csv” in the dataset to show how to convert a csv Lat/Long data to points. First, we need to load the CSV data: housing = read.csv(&quot;o4rtestdata/Affordable_Rental_Housing_Developments.csv&quot;) Then, we need to ensure that no column (intended to be used as a coordinate) is entirely empty or filled with NA values: cleaned_housing &lt;- na.omit(housing) Finally, we start to convert it to points: points_housing &lt;- st_as_sf(cleaned_housing, coords = c(&quot;Longitude&quot;, &quot;Latitude&quot;), crs = 3435) If you want, you can view the resulting sf object: print(points_housing) ## Simple feature collection with 487 features and 12 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -87.80707 ymin: 41.64846 xmax: -87.54012 ymax: 42.01715 ## Projected CRS: NAD83 / Illinois East (ftUS) ## First 10 features: ## Community.Area.Name Community.Area.Number Property.Type ## 2 Rogers Park 1 Senior ## 3 Uptown 3 ARO ## 4 Edgewater 77 Senior ## 5 Roseland 49 Supportive Housing ## 6 Humboldt Park 23 Multifamily ## 7 Grand Boulevard 38 Multifamily ## 8 Woodlawn 42 Multifamily ## 9 Oakland 36 Multifamily ## 10 Oakland 36 Senior ## 11 Near North Side 8 Supportive Housing ## Property.Name Address ## 2 Morse Senior Apts. 6928 N. Wayne Ave. ## 3 The Draper 5050 N. Broadway ## 4 Pomeroy Apts. 5650 N. Kenmore Ave. ## 5 Wentworth Commons 11045 S. Wentworth Ave. ## 6 Nelson Mandela Apts. 607 N. Sawyer Ave. ## 7 Legends South - Gwendolyn Place 4333 S. Michigan Ave. ## 8 Dorchester Apts. 1410 E. 62nd St. ## 9 Oakwood Shrs 1A, 1B, 2A, 2B1 (scattered sites) 3859 S. Vincennes Ave. ## 10 Oakwood Shores Terrace 3755 S. Cottage Grove Ave. ## 11 The Midwest/Carroll Park Apts. 1333 N. Kingsbury St. ## Zip.Code Phone.Number Management.Company Units X.Coordinate ## 2 60626 312-602-6207 Morse Urban Dev. 44 1165844 ## 3 60640 312-818-1722 Flats LLC 35 1167357 ## 4 60660 773-275-7820 Habitat Company 198 1168181 ## 5 60628 773-568-7804 Mercy Housing Lakefront 50 1176951 ## 6 60624 773-227-6332 Bickerdike Apts. 6 1154640 ## 7 60653 773-624-7676 Interstate Realty Management Co. 71 1177924 ## 8 60637 773-572-5500 The Thresholds 67 1186722 ## 9 60653 773-373-1300 The Community Builders 534 1180730 ## 10 60653 773-373-1300 The Community Builders, Inc. 148 1181956 ## 11 60622 312-337-5339 Holsten Real Estate Dev. Corp. 40 1170359 ## Y.Coordinate Location ## 2 1946059 (42.0075737709331, -87.6651711448293) ## 3 1933882 (41.9741295261027, -87.6599553011627) ## 4 1937918 (41.9851867755403, -87.656808676983) ## 5 1831516 (41.6930159120977, -87.6277673462214) ## 6 1903912 (41.8921534052465, -87.7075265659001) ## 7 1876178 (41.815550396096, -87.6228565224104) ## 8 1864210 (41.782505219358, -87.5909616432556) ## 9 1879251 (41.8239192006736, -87.6124684434156) ## 10 1880135 (41.8263173139507, -87.6079454471381) ## 11 1908980 (41.9057310022859, -87.6496459663701) ## geometry ## 2 POINT (-87.66517 42.00757) ## 3 POINT (-87.65996 41.97413) ## 4 POINT (-87.65681 41.98519) ## 5 POINT (-87.62777 41.69302) ## 6 POINT (-87.70753 41.89215) ## 7 POINT (-87.62286 41.81555) ## 8 POINT (-87.59096 41.78251) ## 9 POINT (-87.61247 41.82392) ## 10 POINT (-87.60795 41.82632) ## 11 POINT (-87.64965 41.90573) 4.4 Prepare Spatial Data In this section, we will go through the basic environment setup and spatial data preparation for the further operations and analysis. 4.4.1 Load Spatial Data We need to load the spatial data (shapefile). All the data used for this one assignment can be found here here. Remember, this type of data is actually comprised of multiple files. All need to be present in order to read correctly. Chi_tracts = st_read(&quot;o4rtestdata/geo_export_aae47441-adab-4aca-8cb0-2e0c0114096e.shp&quot;) ## Reading layer `geo_export_aae47441-adab-4aca-8cb0-2e0c0114096e&#39; from data source `/Users/yilinlyu/Documents/sdohplace-toolkit/o4rtestdata/geo_export_aae47441-adab-4aca-8cb0-2e0c0114096e.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 801 features and 9 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -87.94025 ymin: 41.64429 xmax: -87.52366 ymax: 42.02392 ## Geodetic CRS: WGS84(DD) Always inspect data when loading in. First we look at a non-spatial view. head(Chi_tracts) ## Simple feature collection with 6 features and 9 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -87.68822 ymin: 41.72902 xmax: -87.62394 ymax: 41.87455 ## Geodetic CRS: WGS84(DD) ## commarea commarea_n countyfp10 geoid10 name10 namelsad10 notes ## 1 44 44 031 17031842400 8424 Census Tract 8424 &lt;NA&gt; ## 2 59 59 031 17031840300 8403 Census Tract 8403 &lt;NA&gt; ## 3 34 34 031 17031841100 8411 Census Tract 8411 &lt;NA&gt; ## 4 31 31 031 17031841200 8412 Census Tract 8412 &lt;NA&gt; ## 5 32 32 031 17031839000 8390 Census Tract 8390 &lt;NA&gt; ## 6 28 28 031 17031838200 8382 Census Tract 8382 &lt;NA&gt; ## statefp10 tractce10 geometry ## 1 17 842400 POLYGON ((-87.62405 41.7302... ## 2 17 840300 POLYGON ((-87.68608 41.8229... ## 3 17 841100 POLYGON ((-87.62935 41.8528... ## 4 17 841200 POLYGON ((-87.68813 41.8556... ## 5 17 839000 POLYGON ((-87.63312 41.8744... ## 6 17 838200 POLYGON ((-87.66782 41.8741... Note the last column – this is a spatially enabled column. The data is no longer a ‘shapefile’ but an `sf’ object, comprised of polygons. We can use a baseR function to view the spatial dimension. The sf framework enables previews of each attribute in our spatial file. plot(Chi_tracts) Check out the data structure of this file. str(Chi_tracts) ## Classes &#39;sf&#39; and &#39;data.frame&#39;: 801 obs. of 10 variables: ## $ commarea : chr &quot;44&quot; &quot;59&quot; &quot;34&quot; &quot;31&quot; ... ## $ commarea_n: num 44 59 34 31 32 28 65 53 76 77 ... ## $ countyfp10: chr &quot;031&quot; &quot;031&quot; &quot;031&quot; &quot;031&quot; ... ## $ geoid10 : chr &quot;17031842400&quot; &quot;17031840300&quot; &quot;17031841100&quot; &quot;17031841200&quot; ... ## $ name10 : chr &quot;8424&quot; &quot;8403&quot; &quot;8411&quot; &quot;8412&quot; ... ## $ namelsad10: chr &quot;Census Tract 8424&quot; &quot;Census Tract 8403&quot; &quot;Census Tract 8411&quot; &quot;Census Tract 8412&quot; ... ## $ notes : chr NA NA NA NA ... ## $ statefp10 : chr &quot;17&quot; &quot;17&quot; &quot;17&quot; &quot;17&quot; ... ## $ tractce10 : chr &quot;842400&quot; &quot;840300&quot; &quot;841100&quot; &quot;841200&quot; ... ## $ geometry :sfc_POLYGON of length 801; first list element: List of 1 ## ..$ : num [1:243, 1:2] -87.6 -87.6 -87.6 -87.6 -87.6 ... ## ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;XY&quot; &quot;POLYGON&quot; &quot;sfg&quot; ## - attr(*, &quot;sf_column&quot;)= chr &quot;geometry&quot; ## - attr(*, &quot;agr&quot;)= Factor w/ 3 levels &quot;constant&quot;,&quot;aggregate&quot;,..: NA NA NA NA NA NA NA NA NA ## ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;commarea&quot; &quot;commarea_n&quot; &quot;countyfp10&quot; &quot;geoid10&quot; ... 4.4.2 Change Projections/CRS A Coordinate Reference System (CRS) is crucial for mapping the Earth’s three-dimensional surface onto a flat, two-dimensional map. It defines how to project the Earth’s surface, which is vital because different CRSs can make the same location appear differently on maps. This means choosing the right CRS is essential for accurate spatial analysis and mapping. In practice, especially when using software like R, it’s important to check and adjust the CRS of your data to ensure consistency across your project. This helps in avoiding misinterpretations and errors in your spatial analysis. First, check out the coordinate reference system. st_crs(Chi_tracts) ## Coordinate Reference System: ## User input: WGS84(DD) ## wkt: ## GEOGCRS[&quot;WGS84(DD)&quot;, ## DATUM[&quot;WGS84&quot;, ## ELLIPSOID[&quot;WGS84&quot;,6378137,298.257223563, ## LENGTHUNIT[&quot;metre&quot;,1, ## ID[&quot;EPSG&quot;,9001]]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## CS[ellipsoidal,2], ## AXIS[&quot;geodetic longitude&quot;,east, ## ORDER[1], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## AXIS[&quot;geodetic latitude&quot;,north, ## ORDER[2], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]]] To transform our CRS, we use the st_transform function. Let’s choose a projection that is focused on Illinois, and uses distance as feet or meters, to make it a bit more accessible for our work. EPSG:3435 is a good fit: Chi_tracts.3435 &lt;- st_transform(Chi_tracts, &quot;EPSG:3435&quot;) # Chi_tracts.3435 &lt;- st_transform(Chi_tracts, 3435) st_crs(Chi_tracts.3435) ## Coordinate Reference System: ## User input: EPSG:3435 ## wkt: ## PROJCRS[&quot;NAD83 / Illinois East (ftUS)&quot;, ## BASEGEOGCRS[&quot;NAD83&quot;, ## DATUM[&quot;North American Datum 1983&quot;, ## ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## ID[&quot;EPSG&quot;,4269]], ## CONVERSION[&quot;SPCS83 Illinois East zone (US Survey feet)&quot;, ## METHOD[&quot;Transverse Mercator&quot;, ## ID[&quot;EPSG&quot;,9807]], ## PARAMETER[&quot;Latitude of natural origin&quot;,36.6666666666667, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8801]], ## PARAMETER[&quot;Longitude of natural origin&quot;,-88.3333333333333, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8802]], ## PARAMETER[&quot;Scale factor at natural origin&quot;,0.999975, ## SCALEUNIT[&quot;unity&quot;,1], ## ID[&quot;EPSG&quot;,8805]], ## PARAMETER[&quot;False easting&quot;,984250, ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219], ## ID[&quot;EPSG&quot;,8806]], ## PARAMETER[&quot;False northing&quot;,0, ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219], ## ID[&quot;EPSG&quot;,8807]]], ## CS[Cartesian,2], ## AXIS[&quot;easting (X)&quot;,east, ## ORDER[1], ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219]], ## AXIS[&quot;northing (Y)&quot;,north, ## ORDER[2], ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219]], ## USAGE[ ## SCOPE[&quot;Engineering survey, topographic mapping.&quot;], ## AREA[&quot;United States (USA) - Illinois - counties of Boone; Champaign; Clark; Clay; Coles; Cook; Crawford; Cumberland; De Kalb; De Witt; Douglas; Du Page; Edgar; Edwards; Effingham; Fayette; Ford; Franklin; Gallatin; Grundy; Hamilton; Hardin; Iroquois; Jasper; Jefferson; Johnson; Kane; Kankakee; Kendall; La Salle; Lake; Lawrence; Livingston; Macon; Marion; Massac; McHenry; McLean; Moultrie; Piatt; Pope; Richland; Saline; Shelby; Vermilion; Wabash; Wayne; White; Will; Williamson.&quot;], ## BBOX[37.06,-89.28,42.5,-87.02]], ## ID[&quot;EPSG&quot;,3435]] plot(st_geometry(Chi_tracts.3435), border = &quot;gray&quot;, lwd = 2, main = &quot;NAD83 / Illinois East (ftUS)&quot;, sub=&quot;topo mapping &amp; survey use&quot;) 4.4.3 Refine Basic Map Now we’ll switch to a more extensive cartographic mapping package, tmap. We approach mapping with one layer at a time. Always start with the object you want to map by calling it with the tm_shape function. Then, at least one descriptive/styling function follows. There are hundreds of variations and paramater specifications, so take your time in exploring tmap and the options. Here we style the tracts with some semi-transparent borders. library(tmap) ## Breaking News: tmap 3.x is retiring. Please test v4, e.g. with ## remotes::install_github(&#39;r-tmap/tmap&#39;) tm_shape(Chi_tracts) + tm_borders(alpha=0.5) Next we fill the tracts with a light gray, and adjust the color and transparency of borders. We also add a scale bar, positioning it to the left and having a thickness of 0.8 units, and turn off the frame. tm_shape(Chi_tracts) + tm_fill(col = &quot;gray90&quot;) + tm_borders(alpha=0.2, col = &quot;gray10&quot;) + tm_scale_bar(position = (&quot;left&quot;), lwd = 0.8) + tm_layout(frame = F) Check out https://rdrr.io/cran/tmap/man/tm_polygons.html for more ideas! 4.4.4 Overlay Zip Code Boundaries How do census tract areas correspond to zip codes? While tracts better represent neighborhoods, often times we are stuck with zip code level scale in healh research. Here we’ll make a reference map to highlight tract distribution across each zip code. First, we read in zip code boundaries. This data was downloaded directly from the City of Chicago Data Portal as a shapefile. Chi_Zips = st_read(&quot;o4rtestdata/geo_export_54bc15d8-5ef5-40e4-8f72-bb0c6dbac9a5.shp&quot;) ## Reading layer `geo_export_54bc15d8-5ef5-40e4-8f72-bb0c6dbac9a5&#39; from data source `/Users/yilinlyu/Documents/sdohplace-toolkit/o4rtestdata/geo_export_54bc15d8-5ef5-40e4-8f72-bb0c6dbac9a5.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 61 features and 4 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -87.94011 ymin: 41.64454 xmax: -87.52414 ymax: 42.02304 ## Geodetic CRS: WGS84(DD) Next, we layer the new shape in – on top of the tracts. We use a thicker border, and try out a new color. Experiment! ## FIRST LAYER: CENSUS TRACT BOUNADRIES tm_shape(Chi_tracts.3435) + tm_fill(col = &quot;gray90&quot;) + tm_borders(alpha=0.2, col = &quot;gray10&quot;) + ## SECOND LAYER: ZIP CODE BOUNDARIES WITH LABEL tm_shape(Chi_Zips) + tm_borders(lwd = 2, col = &quot;#0099CC&quot;) + tm_text(&quot;zip&quot;, size = 0.7) + ## MORE CARTOGRAPHIC STYLE tm_scale_bar(position = (&quot;left&quot;), lwd = 0.8) + tm_layout(frame = F) 4.5 Geocode Addresses to Points 4.5.1 Prepare Address Data If you start with only addresses, you’ll need to geocode. Our methadone maintenance provider dataset is only available as such. Addresses are comprised of characeters that reference a specific place. We will use the network topology service of a Geocoder to translate that address to a coordinate in some CRS. First we load the tidygeocoder to get our geocoding done. Note, this uses the interent to process, so is not suitable for HIPPA protected data like individual, living person addresses. For offline geocoders, check out Pelias or ESRI. library(tidygeocoder) Let’s read in and inspect data for methadone maintenance providers. Note, these addresses were made available by SAMSHA, and are known as publicly available information. An additional analysis could call each service to check on access to medication during COVID in Septmber 2020, and the list would be updated further. methadoneClinics &lt;- read.csv(&quot;o4rtestdata/chicago_methadone_nogeometry.csv&quot;) head(methadoneClinics) ## X Name ## 1 1 Chicago Treatment and Counseling Center, Inc. ## 2 2 Sundace Methadone Treatment Center, LLC ## 3 3 Soft Landing Interventions/DBA Symetria Recovery of Lakeview ## 4 4 PDSSC - Chicago, Inc. ## 5 5 Center for Addictive Problems, Inc. ## 6 6 Family Guidance Centers, Inc. ## Address City State Zip ## 1 4453 North Broadway st. Chicago IL 60640 ## 2 4545 North Broadway St. Chicago IL 60640 ## 3 3934 N. Lincoln Ave. Chicago IL 60613 ## 4 2260 N. Elston Ave. Chicago IL 60614 ## 5 609 N. Wells St. Chicago IL 60654 ## 6 310 W. Chicago Ave. Chicago IL 60654 Let’s geocode one address first, just to make sure our system is working. We’ll use the “cascade” method which use the US Census and OpenStreetMap geocoders. These two services are the main options with tidygeocoder. sample &lt;- geo(&quot;2260 N. Elston Ave. Chicago, IL&quot;, lat = latitude, long = longitude, method = &#39;cascade&#39;) ## Warning: The `method` argument of `geo()` cannot be &quot;cascade&quot; as of tidygeocoder 1.0.4. ## ℹ Please use `geocode_combine()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. ## Passing 1 address to the US Census single address geocoder ## Query completed in: 0.7 seconds head(sample) ## # A tibble: 1 × 4 ## address latitude longitude geo_method ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 2260 N. Elston Ave. Chicago, IL 41.9 -87.7 census As we prepare for geocoding, check out the structure of the dataset. The data should be a character to be read properly. str(methadoneClinics) ## &#39;data.frame&#39;: 27 obs. of 6 variables: ## $ X : int 1 2 3 4 5 6 7 8 9 10 ... ## $ Name : chr &quot;Chicago Treatment and Counseling Center, Inc.&quot; &quot;Sundace Methadone Treatment Center, LLC&quot; &quot;Soft Landing Interventions/DBA Symetria Recovery of Lakeview&quot; &quot;PDSSC - Chicago, Inc.&quot; ... ## $ Address: chr &quot;4453 North Broadway st.&quot; &quot;4545 North Broadway St.&quot; &quot;3934 N. Lincoln Ave.&quot; &quot;2260 N. Elston Ave.&quot; ... ## $ City : chr &quot;Chicago&quot; &quot;Chicago&quot; &quot;Chicago&quot; &quot;Chicago&quot; ... ## $ State : chr &quot;IL&quot; &quot;IL&quot; &quot;IL&quot; &quot;IL&quot; ... ## $ Zip : int 60640 60640 60613 60614 60654 60654 60651 60607 60607 60616 ... We need to clean the data a bit. We’ll add a new column for a full address, as required by the geocoding service. When you use a geocoding service, be sure to read the documentation and understand how the data needs to be formatted for input. methadoneClinics$fullAdd &lt;- paste(as.character(methadoneClinics$Address), as.character(methadoneClinics$City), as.character(methadoneClinics$State), as.character(methadoneClinics$Zip)) We’re ready to go! Batch geocode with one function, and inspect: geoCodedClinics &lt;- geocode(methadoneClinics, address = &#39;fullAdd&#39;, lat = latitude, long = longitude, method = &#39;cascade&#39;) ## Passing 27 addresses to the US Census batch geocoder ## Query completed in: 0.4 seconds head(geoCodedClinics) ## # A tibble: 6 × 10 ## X Name Address City State Zip fullAdd latitude longitude geo_method ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 Chicago… 4453 N… Chic… IL 60640 4453 N… 42.0 -87.7 census ## 2 2 Sundace… 4545 N… Chic… IL 60640 4545 N… 42.0 -87.7 census ## 3 3 Soft La… 3934 N… Chic… IL 60613 3934 N… 42.0 -87.7 census ## 4 4 PDSSC -… 2260 N… Chic… IL 60614 2260 N… 41.9 -87.7 census ## 5 5 Center … 609 N.… Chic… IL 60654 609 N.… 41.9 -87.6 census ## 6 6 Family … 310 W.… Chic… IL 60654 310 W.… 41.9 -87.6 census There were two that didn’t geocode correctly. You can inspect further. This could involve a quick check for spelling issues; or, searching the address and pulling the lat/long using Google Maps and inputting manually. Or, if we are concerned it’s a human or unknown error, we could omit. For this exercise we’ll just omit the two clinics that didn’t geocode correctly. geoCodedClinics2 &lt;- na.omit(geoCodedClinics) 4.5.2 Convert to Spatial Data This is not spatial data yet! To convert a static file to spatial data, we use the powerful st_as_sf function from sf. Indicate the x,y parameters (=longitude, latitude) and the coordinate reference system used. Our geocoding service used the standard EPSG:4326, so we input that here. library(sf) methadoneSf &lt;- st_as_sf(geoCodedClinics2, coords = c( &quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) 4.5.3 Basic Map of Points For a really simple map of points – to ensure they were geocoded and converted to spatial data correctly, we use tmap. We’ll use the interactive version to view. library(tmap) tmap_mode(&quot;view&quot;) tm_shape(methadoneSf) + tm_dots() If your points didn’t plot correctly: Did you flip the longitude/latitude values? Did you input the correct CRS? Those two issues are the most common errors. 4.5.4 Overlay Points &amp; Style Let’s add our zip code map from the previous module. First load the data, then overlay. Chi_Zipsf &lt;- st_read(&quot;o4rtestdata/ChiZipMaster1.geojson&quot;) ## Reading layer `ChiZipMaster1&#39; from data source ## `/Users/yilinlyu/Documents/sdohplace-toolkit/o4rtestdata/ChiZipMaster1.geojson&#39; ## using driver `GeoJSON&#39; ## Simple feature collection with 540 features and 31 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -87.87596 ymin: 41.64454 xmax: -87.52414 ymax: 42.02304 ## Geodetic CRS: WGS 84 With this overlay, we’ll add a “hack” to include the methadone clinic points in a legend. tmap_mode(&quot;plot&quot;) ## tmap mode set to plotting ## 1st layer (gets plotted first) tm_shape(Chi_Zipsf) + tm_fill(&quot;Case.Rate...Cumulative&quot;, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, n=4, title = &quot;COVID Rt&quot;) + ## 2nd layer (overlay) tm_shape(methadoneSf) + tm_dots(size = 0.2, col = &quot;gray20&quot;) + ## &quot;Hack&quot; a manual symbology for dots in the legend tm_add_legend(&quot;symbol&quot;, col = &quot;gray20&quot;, size = .2, labels = &quot;Methadone MOUD&quot;) + ## Cartographic Styling tm_layout(legend.outside = TRUE, legend.outside.position = &quot;right&quot;) 4.6 Merge SDOH Data to Boundary Dataset From here, we can integrate more data. Let’s try a different point dataset – Affordable Rental Housing Developments, as made available by the City of Chicago Data Portal. This could be interesting for a number of different reasons – maybe we hypothesize better outcomes are associated with better access to affordable housing options? Or, we hypothesize the opposite, that mean distance to more population dense housing locations is vulnerable to airborne disease? For this example, we’ll think about this dataset as access to secure and affordable housing. Persons with lower incomes residing in places with fewer developments may be more vulnerable to housing insecurity -&gt; impacts health. AffHousing &lt;- read.csv(&quot;o4rtestdata/Affordable_Rental_Housing_Developments.csv&quot;) head(AffHousing) ## Community.Area.Name Community.Area.Number Property.Type ## 1 Englewood 68 Veterans ## 2 Rogers Park 1 Senior ## 3 Uptown 3 ARO ## 4 Edgewater 77 Senior ## 5 Roseland 49 Supportive Housing ## 6 Humboldt Park 23 Multifamily ## Property.Name Address Zip.Code Phone.Number ## 1 Hope Manor Village 5900-6100 S. Green/Peoria/Sangamon 60621 312-564-2393 ## 2 Morse Senior Apts. 6928 N. Wayne Ave. 60626 312-602-6207 ## 3 The Draper 5050 N. Broadway 60640 312-818-1722 ## 4 Pomeroy Apts. 5650 N. Kenmore Ave. 60660 773-275-7820 ## 5 Wentworth Commons 11045 S. Wentworth Ave. 60628 773-568-7804 ## 6 Nelson Mandela Apts. 607 N. Sawyer Ave. 60624 773-227-6332 ## Management.Company Units X.Coordinate Y.Coordinate Latitude ## 1 Volunteers of America Illinois 36 NA NA NA ## 2 Morse Urban Dev. 44 1165844 1946059 42.00757 ## 3 Flats LLC 35 1167357 1933882 41.97413 ## 4 Habitat Company 198 1168181 1937918 41.98519 ## 5 Mercy Housing Lakefront 50 1176951 1831516 41.69302 ## 6 Bickerdike Apts. 6 1154640 1903912 41.89215 ## Longitude Location ## 1 NA ## 2 -87.66517 (42.0075737709331, -87.6651711448293) ## 3 -87.65996 (41.9741295261027, -87.6599553011627) ## 4 -87.65681 (41.9851867755403, -87.656808676983) ## 5 -87.62777 (41.6930159120977, -87.6277673462214) ## 6 -87.70753 (41.8921534052465, -87.7075265659001) There were a few data points with odd inputs and null values. Remember, we can’t convert any null values to spatial coordinates. Again, in an ideal context, you would explore and understand what is happening, systematically. In our experiment, we’ll omit nulls. AffHousing &lt;- na.omit(AffHousing) Look at the structure of the object. str(AffHousing) ## &#39;data.frame&#39;: 487 obs. of 14 variables: ## $ Community.Area.Name : chr &quot;Rogers Park&quot; &quot;Uptown&quot; &quot;Edgewater&quot; &quot;Roseland&quot; ... ## $ Community.Area.Number: int 1 3 77 49 23 38 42 36 36 8 ... ## $ Property.Type : chr &quot;Senior&quot; &quot;ARO&quot; &quot;Senior&quot; &quot;Supportive Housing&quot; ... ## $ Property.Name : chr &quot;Morse Senior Apts.&quot; &quot;The Draper&quot; &quot;Pomeroy Apts.&quot; &quot;Wentworth Commons&quot; ... ## $ Address : chr &quot;6928 N. Wayne Ave.&quot; &quot;5050 N. Broadway&quot; &quot;5650 N. Kenmore Ave.&quot; &quot;11045 S. Wentworth Ave.&quot; ... ## $ Zip.Code : int 60626 60640 60660 60628 60624 60653 60637 60653 60653 60622 ... ## $ Phone.Number : chr &quot;312-602-6207&quot; &quot;312-818-1722&quot; &quot;773-275-7820&quot; &quot;773-568-7804&quot; ... ## $ Management.Company : chr &quot;Morse Urban Dev.&quot; &quot;Flats LLC&quot; &quot;Habitat Company&quot; &quot;Mercy Housing Lakefront&quot; ... ## $ Units : int 44 35 198 50 6 71 67 534 148 40 ... ## $ X.Coordinate : num 1165844 1167357 1168181 1176951 1154640 ... ## $ Y.Coordinate : num 1946059 1933882 1937918 1831516 1903912 ... ## $ Latitude : num 42 42 42 41.7 41.9 ... ## $ Longitude : num -87.7 -87.7 -87.7 -87.6 -87.7 ... ## $ Location : chr &quot;(42.0075737709331, -87.6651711448293)&quot; &quot;(41.9741295261027, -87.6599553011627)&quot; &quot;(41.9851867755403, -87.656808676983)&quot; &quot;(41.6930159120977, -87.6277673462214)&quot; ... ## - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int 1 ## ..- attr(*, &quot;names&quot;)= chr &quot;1&quot; In this dataset, we can see coordinate information is already included – twice! You’re looking at 2 different types of coordinate systems. We’ll use “Longitude” and “Latitude” to represent X,Y and an ESPG of 4326. We’re guessing, and hopeful. AffHousingSf &lt;- st_as_sf(AffHousing, coords = c(&quot;Longitude&quot;, &quot;Latitude&quot;), crs = 4326) We can now map the data for a quick view – does this look like Chicago, hopefully? tm_shape(AffHousingSf) + tm_bubbles(&quot;Units&quot;, col = &quot;purple&quot;, style = &quot;sd&quot;) 4.7 Graduated Symbology &amp; Choropleth Map Previously we mapped points as dots. We literally used the tm_dots() function to do so. Another option is changing the size of the point, according to some attribute of the data. In this dataset, we see an attribute field that gives us the total number of units per housing site. Let’s use a graduated symbology, with the tm_bubbles() function, to map these points. That way points with more units will be bigger, and not all places are weighted the same visually. tm_shape(Chi_Zipsf) + tm_polygons(col = &quot;gray80&quot;) + tm_shape(AffHousingSf) + tm_bubbles(&quot;Units&quot;, col = &quot;purple&quot;) Let’s map everything at once, and explore which zip codes are the most vulnerable to persons with OUD during the pandemic in September 2020, based on the information we have here? ## Zip Codes with Labels tm_shape(Chi_Zipsf) + tm_fill(&quot;Case.Rate...Cumulative&quot;, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, n=4, title = &quot;COVID Rt&quot;) + ## Affordable Housing Units tm_shape(AffHousingSf) + tm_bubbles(&quot;Units&quot;) + ## Methadone MOUD tm_shape(methadoneSf) + tm_dots(size = 0.2, col = &quot;gray20&quot;) + ## Cartographic Styling tm_add_legend(&quot;symbol&quot;, col = &quot;gray20&quot;, size = .2, labels = &quot;Methadone MOUD&quot;) + tm_layout(legend.outside = TRUE, legend.outside.position = &quot;right&quot;) In RStudio, you could zoom into the plot you created to get a better view. Save as an image, or save as a webpage! Save any data you need from this session. st_write(methadoneSf, dsn = &quot;o4rtestdata/methadoneMOUD.geojson&quot;) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
>>>>>>> Stashed changes
