[["04-dataR.html", "A Data Wrangling in R A.1 Environmental Setup A.2 Intro to Spatial Data A.3 Coordinate Reference Systems A.4 Converting to Spatial Data A.5 Convert to Spatial Data A.6 Merge Data sets A.7 Inspect Data Resources", " A Data Wrangling in R In this part of our toolkit, we’re going to learn how to do the same things we did with Chapter 4 - Spatial Data Wrangling, but this time, we’ll use R code to handle our spatial data. Getting Started R is a great choice for starting in data science because it’s built for it. It’s not just a programming language, it is a whole system with tools and libraries made to help you think and work like a data scientist easily. We assume a basic knowledge of R and coding languages for these toolkits. For most of the tutorials in this toolkit, you’ll need to have R and RStudio downloaded and installed on your system. You should be able to install packages, know how to find the address to a folder on your computer system, and have very basic familiarity with R. Tutorials for R If you are new to R, we recommend the following intro-level tutorials provided through installation guides. You can also refer to this R for Social Scientists tutorial developed by Data Carpentry for a refresher. You can also visit the RStudio Education page to select a learning path tailored to your experience level (Beginners, Intermediates, Experts). They offer detailed instructions to learners at different stages of their R journey. A.1 Environmental Setup Getting started with data analysis in R involves a few preliminary steps, including downloading datasets and setting up a working directory. This introduction will guide you through these essential steps to ensure a smooth start to your data analysis journey in R. Download the Activity Datasets Please download and unzip this file to get started: SDOHPlace-DataWrangling.zip Setting Up the Working Directory Setting up a working directory in R is crucial as it defines the location on your computer where your files and scripts will be saved and accessed. You can set the working directory to any folder on your system where you plan to store your datasets and R scripts. To set your working directory, use the setwd(\"/path/to/your/directory\") and specify the path to your desired directory. Installing &amp; Working with R Libraries Before starting operations related to spatial data, we need to complete an environmental setup. This workshop requires several packages, which can be installed from CRAN: sf: simplifies spatial data manipulation tmap: streamlines thematic map creation dplyr: facilitates data manipulation tidygeocoder: converts addresses to coordinates easily Uncomment to install packages with code snippet below. You only need to install packages once in an R environment. #install.packages(&quot;sf&quot;, &quot;tmap&quot;, &quot;tidygeocoder&quot;, &quot;dplyr&quot;) Installation Tip For Mac users, check out https://github.com/r-spatial/sf for additional tips if you run into errors when installing the sf package. Using homebrew to install gdal usually fixes any remaining issues. Now, loading the required libraries for further steps: library(sf) library(dplyr) library(tmap) A.2 Intro to Spatial Data Spatial data analysis in R provides a robust framework for understanding geographical information, enabling users to explore, visualize, and model spatial relationships directly within their data. Through the integration of specialized packages like sf for spatial data manipulation, ggplot2 and tmap for advanced mapping, and tidygeocoder for geocoding, R becomes a powerful tool for geographic data science. This ecosystem allows researchers and analysts to uncover spatial patterns, analyze geographic trends, and produce detailed maps that convey complex information intuitively. Load Spatial Data We need to load the spatial data (shapefile). Remember, this type of data is actually comprised of multiple files. All need to be present in order to read correctly. Let’s use chicagotracts.shp for practice, which includes the census tracts boundary in Chicago. First, we need to read the shapefile data from where you save it. Chi_tracts = st_read(&quot;SDOHPlace-DataWrangling/chicagotracts.shp&quot;) ## Reading layer `chicagotracts&#39; from data source ## `/Users/maryniakolak/Code/sdhoplace-toolkit/SDOHPlace-DataWrangling/chicagotracts.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 801 features and 9 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -87.94025 ymin: 41.64429 xmax: -87.52366 ymax: 42.02392 ## Geodetic CRS: WGS 84 Always inspect data when loading in. Let’s look at a non-spatial view. head(Chi_tracts) ## Simple feature collection with 6 features and 9 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -87.68822 ymin: 41.72902 xmax: -87.62394 ymax: 41.87455 ## Geodetic CRS: WGS 84 ## commarea commarea_n countyfp10 geoid10 name10 namelsad10 notes ## 1 44 44 031 17031842400 8424 Census Tract 8424 &lt;NA&gt; ## 2 59 59 031 17031840300 8403 Census Tract 8403 &lt;NA&gt; ## 3 34 34 031 17031841100 8411 Census Tract 8411 &lt;NA&gt; ## 4 31 31 031 17031841200 8412 Census Tract 8412 &lt;NA&gt; ## 5 32 32 031 17031839000 8390 Census Tract 8390 &lt;NA&gt; ## 6 28 28 031 17031838200 8382 Census Tract 8382 &lt;NA&gt; ## statefp10 tractce10 geometry ## 1 17 842400 POLYGON ((-87.62405 41.7302... ## 2 17 840300 POLYGON ((-87.68608 41.8229... ## 3 17 841100 POLYGON ((-87.62935 41.8528... ## 4 17 841200 POLYGON ((-87.68813 41.8556... ## 5 17 839000 POLYGON ((-87.63312 41.8744... ## 6 17 838200 POLYGON ((-87.66782 41.8741... Check out the data structure of this file. str(Chi_tracts) ## Classes &#39;sf&#39; and &#39;data.frame&#39;: 801 obs. of 10 variables: ## $ commarea : chr &quot;44&quot; &quot;59&quot; &quot;34&quot; &quot;31&quot; ... ## $ commarea_n: num 44 59 34 31 32 28 65 53 76 77 ... ## $ countyfp10: chr &quot;031&quot; &quot;031&quot; &quot;031&quot; &quot;031&quot; ... ## $ geoid10 : chr &quot;17031842400&quot; &quot;17031840300&quot; &quot;17031841100&quot; &quot;17031841200&quot; ... ## $ name10 : chr &quot;8424&quot; &quot;8403&quot; &quot;8411&quot; &quot;8412&quot; ... ## $ namelsad10: chr &quot;Census Tract 8424&quot; &quot;Census Tract 8403&quot; &quot;Census Tract 8411&quot; &quot;Census Tract 8412&quot; ... ## $ notes : chr NA NA NA NA ... ## $ statefp10 : chr &quot;17&quot; &quot;17&quot; &quot;17&quot; &quot;17&quot; ... ## $ tractce10 : chr &quot;842400&quot; &quot;840300&quot; &quot;841100&quot; &quot;841200&quot; ... ## $ geometry :sfc_POLYGON of length 801; first list element: List of 1 ## ..$ : num [1:243, 1:2] -87.6 -87.6 -87.6 -87.6 -87.6 ... ## ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;XY&quot; &quot;POLYGON&quot; &quot;sfg&quot; ## - attr(*, &quot;sf_column&quot;)= chr &quot;geometry&quot; ## - attr(*, &quot;agr&quot;)= Factor w/ 3 levels &quot;constant&quot;,&quot;aggregate&quot;,..: NA NA NA NA NA NA NA NA NA ## ..- attr(*, &quot;names&quot;)= chr [1:9] &quot;commarea&quot; &quot;commarea_n&quot; &quot;countyfp10&quot; &quot;geoid10&quot; ... The data is no longer a shapefile but an sf object, comprised of polygons. The plot() command in R help to quickly visualizes the geometric shapes of Chicago’s census tracts. The output includes multiple maps because the sf framework enables previews of each attribute in our spatial file. plot(Chi_tracts) A.2.1 Adding a Basemap Then, we can use tmap, a mapping library, in interactive mode to add a basemap layer. It plots the spatial data from Chi_tracts, applies a minimal theme for clarity, and labels the map with a title, offering a straightforward visualization of the area’s census tracts. We stylize the borders of the tract boundaries by making it transparent at 50% (which is equal to an alpha level of 0.5). library(tmap) tmap_mode(&quot;view&quot;) ## tmap mode set to interactive viewing tm_shape(Chi_tracts) + tm_borders(alpha=0.5) + tm_layout(title = &quot;Census Tract Map of Chicago&quot;) Still in the interactive mode (`view’), we can switch to a different basemap. Here we bring in a “Voyager” style map from Carto, a cartographic firm. We’ll make the borders less transparent by adjusting the alpha level. tmap_mode(&quot;view&quot;) ## tmap mode set to interactive viewing tm_basemap(&quot;CartoDB.Voyager&quot;) + tm_shape(Chi_tracts) + tm_borders(alpha=0.8, col = &quot;gray40&quot;) + tm_layout(title = &quot;Census Tract Map of Chicago&quot;) Tip For additional options, you can preview basemaps at the Leaflet Providers Demo. Some basemaps we recommend that work consistently are by: CartoDB (Carto) Open Street Map ESRI Not all basemaps are available anymore, and some require keys that you’d need to add on your own. A.3 Coordinate Reference Systems For this exercise we will use chicagotracts.shp to explore how to change the projection of a spatial dataset in R. First, let’s check out the current coordinate reference system. st_crs(Chi_tracts) ## Coordinate Reference System: ## User input: WGS 84 ## wkt: ## GEOGCRS[&quot;WGS 84&quot;, ## DATUM[&quot;World Geodetic System 1984&quot;, ## ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## CS[ellipsoidal,2], ## AXIS[&quot;latitude&quot;,north, ## ORDER[1], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## AXIS[&quot;longitude&quot;,east, ## ORDER[2], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## ID[&quot;EPSG&quot;,4326]] We can use the st_transform function to transform CRS. When projecting a dataset of Illinois, the most appropriate NAD83 projection would be NAD83 UTM zone 16N. Chicago sits within the area best covered by NAD83 / Illinois East (ftUS) (EPSG:3435). Chi_tracts.3435 &lt;- st_transform(Chi_tracts, &quot;EPSG:3435&quot;) # Chi_tracts.3435 &lt;- st_transform(Chi_tracts, 3435) st_crs(Chi_tracts.3435) ## Coordinate Reference System: ## User input: EPSG:3435 ## wkt: ## PROJCRS[&quot;NAD83 / Illinois East (ftUS)&quot;, ## BASEGEOGCRS[&quot;NAD83&quot;, ## DATUM[&quot;North American Datum 1983&quot;, ## ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## ID[&quot;EPSG&quot;,4269]], ## CONVERSION[&quot;SPCS83 Illinois East zone (US Survey feet)&quot;, ## METHOD[&quot;Transverse Mercator&quot;, ## ID[&quot;EPSG&quot;,9807]], ## PARAMETER[&quot;Latitude of natural origin&quot;,36.6666666666667, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8801]], ## PARAMETER[&quot;Longitude of natural origin&quot;,-88.3333333333333, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8802]], ## PARAMETER[&quot;Scale factor at natural origin&quot;,0.999975, ## SCALEUNIT[&quot;unity&quot;,1], ## ID[&quot;EPSG&quot;,8805]], ## PARAMETER[&quot;False easting&quot;,984250, ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219], ## ID[&quot;EPSG&quot;,8806]], ## PARAMETER[&quot;False northing&quot;,0, ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219], ## ID[&quot;EPSG&quot;,8807]]], ## CS[Cartesian,2], ## AXIS[&quot;easting (X)&quot;,east, ## ORDER[1], ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219]], ## AXIS[&quot;northing (Y)&quot;,north, ## ORDER[2], ## LENGTHUNIT[&quot;US survey foot&quot;,0.304800609601219]], ## USAGE[ ## SCOPE[&quot;Engineering survey, topographic mapping.&quot;], ## AREA[&quot;United States (USA) - Illinois - counties of Boone; Champaign; Clark; Clay; Coles; Cook; Crawford; Cumberland; De Kalb; De Witt; Douglas; Du Page; Edgar; Edwards; Effingham; Fayette; Ford; Franklin; Gallatin; Grundy; Hamilton; Hardin; Iroquois; Jasper; Jefferson; Johnson; Kane; Kankakee; Kendall; La Salle; Lake; Lawrence; Livingston; Macon; Marion; Massac; McHenry; McLean; Moultrie; Piatt; Pope; Richland; Saline; Shelby; Vermilion; Wabash; Wayne; White; Will; Williamson.&quot;], ## BBOX[37.06,-89.28,42.5,-87.02]], ## ID[&quot;EPSG&quot;,3435]] After change the projection, we can plot the map. We’ll swith to the static version of tmap, using the plot mode. tmap_mode(&quot;plot&quot;) ## tmap mode set to plotting tm_shape(Chi_tracts.3435) + tm_borders(alpha=0.5) + tm_layout(main.title =&quot;EPSG:3435 (ft)&quot;, main.title.position = &quot;center&quot;) What if we had used the wrong EPSG code, referencing the wrong projection? Here we’ll transform and plot EPSG Code 3561, a coordinate reference system in Haw’aii. Chi_tracts.3561 &lt;- st_transform(Chi_tracts, &quot;EPSG:3561&quot;) tm_shape(Chi_tracts.3561) + tm_borders(alpha=0.5) + tm_layout(main.title =&quot;EPSG:3561 (ft)&quot;, main.title.position = &quot;center&quot;) It’s obviously not correct – the wrong CRS can cause a load of trouble. Make sure you specify carefully! Refine Basic Map Let’s take a deeper look at the cartographic mapping package, tmap. We approach mapping with one layer at a time. Always start with the object you want to map by calling it with the tm_shape function. Then, at least one descriptive/styling function follows. There are hundreds of variations and paramater specification. Here we style the tracts with some semi-transparent borders. library(tmap) tm_shape(Chi_tracts) + tm_borders(alpha=0.5) Next we fill the tracts with a light gray, and adjust the color and transparency of borders. We also add a scale bar, positioning it to the left and having a thickness of 0.8 units, and turn off the frame. tm_shape(Chi_tracts) + tm_fill(col = &quot;gray90&quot;) + tm_borders(alpha=0.2, col = &quot;gray10&quot;) + tm_scale_bar(position = (&quot;left&quot;), lwd = 0.8) + tm_layout(frame = F) Check out https://rdrr.io/cran/tmap/man/tm_polygons.html for more ideas. A.4 Converting to Spatial Data A.4.1 Convert CSVs to Spatial Data We are using the Affordable_Rental_Housing_Developments.csv in the dataset to show how to convert a csv Lat/Long data to points. First, we need to load the CSV data. housing = read.csv(&quot;SDOHPlace-DataWrangling/Affordable_Rental_Housing_Developments.csv&quot;) Then, we need to ensure that no column (intended to be used as a coordinate) is entirely empty or filled with NA values. cleaned_housing &lt;- na.omit(housing) Inspect the data to confirm it’s doing what you expect it to be doing. What columns will you use to specify the coordinates? In this dataset, we have multiple coordinate options. We’ll use latitude and longitude, or rather, longitude as our X value, and latitude as our Y value. In the data, it’s specified as “Longitude” and “Latitude.” head(cleaned_housing) ## Community.Area.Name Community.Area.Number Property.Type ## 2 Rogers Park 1 Senior ## 3 Uptown 3 ARO ## 4 Edgewater 77 Senior ## 5 Roseland 49 Supportive Housing ## 6 Humboldt Park 23 Multifamily ## 7 Grand Boulevard 38 Multifamily ## Property.Name Address Zip.Code Phone.Number ## 2 Morse Senior Apts. 6928 N. Wayne Ave. 60626 312-602-6207 ## 3 The Draper 5050 N. Broadway 60640 312-818-1722 ## 4 Pomeroy Apts. 5650 N. Kenmore Ave. 60660 773-275-7820 ## 5 Wentworth Commons 11045 S. Wentworth Ave. 60628 773-568-7804 ## 6 Nelson Mandela Apts. 607 N. Sawyer Ave. 60624 773-227-6332 ## 7 Legends South - Gwendolyn Place 4333 S. Michigan Ave. 60653 773-624-7676 ## Management.Company Units X.Coordinate Y.Coordinate Latitude ## 2 Morse Urban Dev. 44 1165844 1946059 42.00757 ## 3 Flats LLC 35 1167357 1933882 41.97413 ## 4 Habitat Company 198 1168181 1937918 41.98519 ## 5 Mercy Housing Lakefront 50 1176951 1831516 41.69302 ## 6 Bickerdike Apts. 6 1154640 1903912 41.89215 ## 7 Interstate Realty Management Co. 71 1177924 1876178 41.81555 ## Longitude Location ## 2 -87.66517 (42.0075737709331, -87.6651711448293) ## 3 -87.65996 (41.9741295261027, -87.6599553011627) ## 4 -87.65681 (41.9851867755403, -87.656808676983) ## 5 -87.62777 (41.6930159120977, -87.6277673462214) ## 6 -87.70753 (41.8921534052465, -87.7075265659001) ## 7 -87.62286 (41.815550396096, -87.6228565224104) Finally, we start to convert it to points. Be sure you use the CRS of the original coordinates recorded. In this case we weren’t sure what CRS that was, so we use EPSG:4326 to test. points_housing &lt;- st_as_sf(cleaned_housing, coords = c(&quot;Longitude&quot;, &quot;Latitude&quot;), crs = 4326) View the resulting sf object with a basemap to confirm they are in the right place. Overlay them on top of the tract data, to confirm they are plotting correctly. ### First Layer tm_shape(Chi_tracts) + tm_borders(lwd = 0.5) + ### Second Layer tm_shape(points_housing) + tm_dots(size = 0.1 ) You can change the tmap_mode to “view” to add a basemap in an interactive setting, and then switch back to “plot” when complete. Because we’e plotting dots using tmap, we’ll use the tm_dots parameter for styling. tmap_mode(&quot;view&quot;) ## tmap mode set to interactive viewing tm_shape(Chi_tracts) + tm_borders(lwd = 0.5) + tm_shape(points_housing) + tm_dots(size = 0.01) tmap_mode(&quot;plot&quot;) ## tmap mode set to plotting We’ll reproject to EPSG:3435, our system standard housing.3435 &lt;- st_transform(points_housing, &quot;EPSG:3435&quot;) A.4.1.1 Write Spatial Data Finally, we can save our points as a spatial dataset. Use ‘st_write’ to write your spatial object in R to a data format of your choice. Here, we’ll write to a geojson file. Uncomment to run this line. #st_write(housing.3435, &quot;housing.geojson&quot;, driver = &quot;GeoJSON&quot;) You could also save as a “housing.shapefile” to get a shapefile format, however you’ll get an error noting that some column names are too long and must be shortened. Shapefile formats have a limit of 10 characters for field names. #st_write(housing.3435, &quot;housing.shp&quot;, driver = &quot;ESRI Shapefile&quot;) The file may still write, but the column names that were too long may be shortened automatically. To change column or field names in R objects, there are dozens of options. Try searching and “googling” different search terms to identify solutions on your own. A.4.2 Geocode Addresses Here, we will use chicago_methadone_nogeometry.csv for practice, which includes methadone centers in Chicago (center names and addresses). First we load the tidygeocoder to get our geocoding done. library(tidygeocoder) Let’s read in and inspect data for methadone maintenance providers. Note, these addresses were made available by SAMSHA, and are known as publicly available information. An additional analysis could call each service to check on access to medication during COVID in Septmber 2020, and the list would be updated further. methadoneClinics &lt;- read.csv(&quot;SDOHPlace-DataWrangling/chicago_methadone_nogeometry.csv&quot;) head(methadoneClinics) ## X Name ## 1 1 Chicago Treatment and Counseling Center, Inc. ## 2 2 Sundace Methadone Treatment Center, LLC ## 3 3 Soft Landing Interventions/DBA Symetria Recovery of Lakeview ## 4 4 PDSSC - Chicago, Inc. ## 5 5 Center for Addictive Problems, Inc. ## 6 6 Family Guidance Centers, Inc. ## Address City State Zip ## 1 4453 North Broadway st. Chicago IL 60640 ## 2 4545 North Broadway St. Chicago IL 60640 ## 3 3934 N. Lincoln Ave. Chicago IL 60613 ## 4 2260 N. Elston Ave. Chicago IL 60614 ## 5 609 N. Wells St. Chicago IL 60654 ## 6 310 W. Chicago Ave. Chicago IL 60654 Let’s geocode one address first, just to make sure our system is working. We’ll use the “cascade” method which use the US Census and OpenStreetMap geocoders. These two services are the main options with tidygeocoder. sample &lt;- geo(&quot;2260 N. Elston Ave. Chicago, IL&quot;, lat = latitude, long = longitude, method = &#39;cascade&#39;) ## Warning: The `method` argument of `geo()` cannot be &quot;cascade&quot; as of tidygeocoder 1.0.4. ## ℹ Please use `geocode_combine()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. ## Passing 1 address to the US Census single address geocoder ## Query completed in: 0.6 seconds head(sample) ## # A tibble: 1 × 4 ## address latitude longitude geo_method ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 2260 N. Elston Ave. Chicago, IL 41.9 -87.7 census As we prepare for geocoding, check out the structure of the dataset. The data should be a character to be read properly. str(methadoneClinics) ## &#39;data.frame&#39;: 27 obs. of 6 variables: ## $ X : int 1 2 3 4 5 6 7 8 9 10 ... ## $ Name : chr &quot;Chicago Treatment and Counseling Center, Inc.&quot; &quot;Sundace Methadone Treatment Center, LLC&quot; &quot;Soft Landing Interventions/DBA Symetria Recovery of Lakeview&quot; &quot;PDSSC - Chicago, Inc.&quot; ... ## $ Address: chr &quot;4453 North Broadway st.&quot; &quot;4545 North Broadway St.&quot; &quot;3934 N. Lincoln Ave.&quot; &quot;2260 N. Elston Ave.&quot; ... ## $ City : chr &quot;Chicago&quot; &quot;Chicago&quot; &quot;Chicago&quot; &quot;Chicago&quot; ... ## $ State : chr &quot;IL&quot; &quot;IL&quot; &quot;IL&quot; &quot;IL&quot; ... ## $ Zip : int 60640 60640 60613 60614 60654 60654 60651 60607 60607 60616 ... We need to clean the data a bit. We’ll add a new column for a full address, as required by the geocoding service. When you use a geocoding service, be sure to read the documentation and understand how the data needs to be formatted for input. methadoneClinics$fullAdd &lt;- paste(as.character(methadoneClinics$Address), as.character(methadoneClinics$City), as.character(methadoneClinics$State), as.character(methadoneClinics$Zip)) We’re ready to go! Batch geocode with one function, and inspect: geoCodedClinics &lt;- geocode(methadoneClinics, address = &#39;fullAdd&#39;, lat = latitude, long = longitude, method = &#39;cascade&#39;) ## Passing 27 addresses to the US Census batch geocoder ## Query completed in: 0.7 seconds head(geoCodedClinics) ## # A tibble: 6 × 10 ## X Name Address City State Zip fullAdd latitude longitude geo_method ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 Chicago… 4453 N… Chic… IL 60640 4453 N… 42.0 -87.7 census ## 2 2 Sundace… 4545 N… Chic… IL 60640 4545 N… 42.0 -87.7 census ## 3 3 Soft La… 3934 N… Chic… IL 60613 3934 N… 42.0 -87.7 census ## 4 4 PDSSC -… 2260 N… Chic… IL 60614 2260 N… 41.9 -87.7 census ## 5 5 Center … 609 N.… Chic… IL 60654 609 N.… 41.9 -87.6 census ## 6 6 Family … 310 W.… Chic… IL 60654 310 W.… 41.9 -87.6 census There were two that didn’t geocode correctly. You can inspect further. This could involve a quick check for spelling issues; or, searching the address and pulling the lat/long using Google Maps and inputting manually. Or, if we are concerned it’s a human or unknown error, we could omit. For this exercise we’ll just omit the two clinics that didn’t geocode correctly. geoCodedClinics2 &lt;- na.omit(geoCodedClinics) A.5 Convert to Spatial Data This is not spatial data yet! To convert a static file to spatial data, we use the powerful st_as_sf function from sf. Indicate the x,y parameters (=longitude, latitude) and the coordinate reference system used. Our geocoding service used the standard EPSG:4326, so we input that here. methadoneSf &lt;- st_as_sf(geoCodedClinics2, coords = c( &quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) Basic Map of Points For a really simple map of points – to ensure they were geocoded and converted to spatial data correctly, we use tmap. We’ll use the interactive version to view. tmap_mode(&quot;view&quot;) tm_shape(methadoneSf) + tm_dots() If your points didn’t plot correctly: Did you flip the longitude/latitude values? Did you input the correct CRS? Those two issues are the most common errors. A.6 Merge Data sets Reshape Data Here, we are trying to use the COVID-19_Cases__Tests__and_Deaths_by_ZIP_Code.csv dataset to practice how to convert long data to a wide data format. We subset to the first two columns, and the sixth column. That gives us the zip code, the reporting week, and cumalative cases of Covid-19. We want each zip code to be a unique row, with cases by week as a columns Choose whatever subset functioon you prefer best! covid = read.csv(&quot;SDOHPlace-DataWrangling/COVID-19_Cases__Tests__and_Deaths_by_ZIP_Code.csv&quot;) covid_clean = covid[,c(1:2, 6)] head(covid_clean) ## ZIP.Code Week.Number Cases...Cumulative ## 1 60603 39 13 ## 2 60604 39 31 ## 3 60611 16 72 ## 4 60611 15 64 ## 5 60615 11 NA ## 6 60603 10 NA Now, we are trying to create a wide data set with the cumulative cases for each week for each zip code. Enter the code and you will see the new wide data format. covid_wide &lt;- reshape(covid_clean, direction = &quot;wide&quot;, idvar = &quot;ZIP.Code&quot;, timevar = &quot;Week.Number&quot;) head(covid_wide) ## ZIP.Code Cases...Cumulative.39 Cases...Cumulative.16 Cases...Cumulative.15 ## 1 60603 13 NA NA ## 2 60604 31 NA NA ## 3 60611 458 72 64 ## 5 60615 644 171 132 ## 31 60605 391 93 65 ## 32 Unknown 240 23 18 ## Cases...Cumulative.11 Cases...Cumulative.10 Cases...Cumulative.12 ## 1 NA NA NA ## 2 NA NA NA ## 3 NA NA 16 ## 5 NA NA 26 ## 31 NA NA 23 ## 32 NA NA NA ## Cases...Cumulative.13 Cases...Cumulative.14 Cases...Cumulative.34 ## 1 NA NA 11 ## 2 NA NA 29 ## 3 41 57 352 ## 5 57 99 567 ## 31 39 52 325 ## 32 NA 9 162 ## Cases...Cumulative.17 Cases...Cumulative.18 Cases...Cumulative.19 ## 1 NA NA NA ## 2 6 11 14 ## 3 80 92 99 ## 5 215 243 274 ## 31 118 135 149 ## 32 33 53 62 ## Cases...Cumulative.20 Cases...Cumulative.31 Cases...Cumulative.22 ## 1 5 9 6 ## 2 17 25 22 ## 3 114 286 139 ## 5 302 526 353 ## 31 155 291 187 ## 32 69 127 97 ## Cases...Cumulative.23 Cases...Cumulative.24 Cases...Cumulative.25 ## 1 6 6 6 ## 2 23 24 24 ## 3 148 152 163 ## 5 364 376 388 ## 31 194 198 215 ## 32 102 106 112 ## Cases...Cumulative.28 Cases...Cumulative.29 Cases...Cumulative.30 ## 1 6 8 9 ## 2 25 25 25 ## 3 223 240 264 ## 5 444 482 506 ## 31 247 263 277 ## 32 120 124 126 ## Cases...Cumulative.32 Cases...Cumulative.33 Cases...Cumulative.26 ## 1 10 11 6 ## 2 25 25 25 ## 3 305 333 175 ## 5 539 556 401 ## 31 304 312 229 ## 32 132 142 113 ## Cases...Cumulative.27 Cases...Cumulative.36 Cases...Cumulative.38 ## 1 6 11 13 ## 2 25 31 31 ## 3 196 391 435 ## 5 418 606 629 ## 31 235 354 379 ## 32 116 186 216 ## Cases...Cumulative.21 Cases...Cumulative.35 Cases...Cumulative.37 ## 1 6 11 13 ## 2 20 30 31 ## 3 124 371 411 ## 5 332 588 613 ## 31 169 333 364 ## 32 92 178 201 ## Cases...Cumulative.40 ## 1 14 ## 2 31 ## 3 478 ## 5 651 ## 31 399 ## 32 288 Join by Attribute Here, we’ll merge data sets with a common variable in R. Merging the cumulative case data set you created in the last section to zip code spatial data (ChiZipMaster1.geojson) will allow you to map the case data. You’ll be merging the case data and spatial data using the zip codes field of each dataset. We’ve cleaned our covid case data already, but not all values under the zipcode column are valid. There is a row has a value of “unkown”, so let’s remove that. covid_wide_clean &lt;- covid_wide %&gt;% filter(ZIP.Code != &quot;unknown&quot; &amp; !is.na(ZIP.Code)) Then, we need to load the zipcode data. zipcode &lt;- st_read(&quot;SDOHPlace-DataWrangling/ChiZipMaster1.geojson&quot;) ## Reading layer `ChiZipMaster1&#39; from data source ## `/Users/maryniakolak/Code/sdhoplace-toolkit/SDOHPlace-DataWrangling/ChiZipMaster1.geojson&#39; ## using driver `GeoJSON&#39; ## Simple feature collection with 540 features and 31 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -87.87596 ymin: 41.64454 xmax: -87.52414 ymax: 42.02304 ## Geodetic CRS: WGS 84 You’ll notice that the zip codes are repeated in the zip code data set, and needs to be cleaned before we can continue with merging the data. zipcode_unique &lt;- distinct(zipcode) zipcode_unique &lt;- zipcode %&gt;% group_by(zip) %&gt;% slice(1) %&gt;% ungroup() Now, the two datasets are ready to join together by the zipcode. Make sure to check they have been joined successully. We’ll have these joined datasets be called Chi_Zipsf, to denote a final zip code master dataset. Chi_Zipsf &lt;- zipcode_unique %&gt;% left_join(covid_wide_clean, by = c(&quot;zip&quot; = &quot;ZIP.Code&quot;)) We’ll reproject to EPSG:3435, the standard used in our study area. Chi_Zipsf.3435 &lt;- st_transform(Chi_Zipsf, 3435) Join by Location We’ll create a spatial join with the housing and zip code data we’ve brought in. In this example, we want to join zip-level data to the Rental Housing Developments, so we can identify which zips they are within. First, let’s try “sticking” all the zip code data too the housing points, intersecting zip codes with housing developments. To do this, both datasets will need to be in the same CRS. We have already standardized both using EPSG:3435. Housing.f &lt;- st_join(housing.3435, Chi_Zipsf.3435, join = st_intersects) Don’t forget to inspect the data. Uncomment to explore! #head(Housing.f) We could also flip things around, and try to count how many developments intersect each zip code We can use lengths() to find out how many items are present in a vector. Here, Chi_Zipsf.3435$TotHousing &lt;- lengths(st_intersects(Chi_Zipsf.3435, housing.3435)) head(Chi_Zipsf.3435) ## Simple feature collection with 6 features and 63 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: 1173038 ymin: 1889918 xmax: 1183259 ymax: 1902959 ## Projected CRS: NAD83 / Illinois East (ftUS) ## # A tibble: 6 × 64 ## zip objectid shape_area shape_len Case.Rate...Cumulative year totPopE ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 60601 27 9166246. 19805. 1451. 2018 14675 ## 2 60602 26 4847125. 14448. 1688. 2018 1244 ## 3 60603 19 4560229. 13673. 1107. 2018 1174 ## 4 60604 48 4294902. 12246. 3964. 2018 782 ## 5 60605 20 36301276. 37973. 1421. 2018 27519 ## 6 60606 31 6766411. 12040. 2290. 2018 3101 ## # ℹ 57 more variables: whiteP &lt;dbl&gt;, blackP &lt;dbl&gt;, amIndP &lt;dbl&gt;, asianP &lt;dbl&gt;, ## # pacIsP &lt;dbl&gt;, otherP &lt;dbl&gt;, hispP &lt;dbl&gt;, noHSP &lt;dbl&gt;, age0_4 &lt;int&gt;, ## # age5_14 &lt;int&gt;, age15_19 &lt;int&gt;, age20_24 &lt;int&gt;, age15_44 &lt;int&gt;, ## # age45_49 &lt;int&gt;, age50_54 &lt;int&gt;, age55_59 &lt;int&gt;, age60_64 &lt;int&gt;, ## # ageOv65 &lt;int&gt;, ageOv18 &lt;int&gt;, age18_64 &lt;int&gt;, a15_24P &lt;dbl&gt;, und45P &lt;dbl&gt;, ## # ovr65P &lt;dbl&gt;, disbP &lt;dbl&gt;, geometry &lt;MULTIPOLYGON [US_survey_foot]&gt;, ## # Cases...Cumulative.39 &lt;int&gt;, Cases...Cumulative.16 &lt;int&gt;, … A.7 Inspect Data A.7.1 Thematic Maps To inspect data from a spatial perspective, we can create a series of choropleth maps. Example 1. Number of Affordable Housing Developments per Zip Code Choose the variable “TotHousing” to map total developments per zip coode, as we calculated previously. Here we’ll map using Jenks data breaks, with a Blue to Purple palette, and four bins (or groups of data to be plotted). A histogram of the data is plotted, visualizing where breaks occured in the data to generate the map. tmap_mode(&quot;plot&quot;) tm_shape(Chi_Zipsf.3435) + tm_polygons(&quot;TotHousing&quot;, legend.hist = TRUE, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, n=4, title = &quot;Housing Dev.&quot;) + tm_layout(legend.outside = TRUE, legend.outside.position = &quot;right&quot;) Example 2. Number of COVID-19 Cases per Zip Code Let’s do the same, but plut a different variable. Select a different variable name as your parameter in the ‘tm_fill’ parameter. tm_shape(Chi_Zipsf.3435) + tm_polygons(&quot;Case.Rate...Cumulative&quot;, legend.hist = TRUE, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, n=4, title = &quot;COVID Case Rate&quot;) + tm_layout(legend.outside = TRUE, legend.outside.position = &quot;right&quot;) A.7.2 Map Overlay Example 1. Afforfable Housing Developments &amp; Zipcode Boundaries We previously translated the housing dataset from a CSV to a spatial object. Let’s take an attribute connect with each point, the total number of units per housing development, and visualize as a graduated symbology. Points with more units will be bigger, and not all places are weighted the same visually. We use the “style” parameter to aadd a standard deviation data classification break. Check out tmap documentation for more options, like quantiles, natural jenks, or other options. tm_shape(housing.3435) + tm_bubbles(&quot;Units&quot;, col = &quot;purple&quot;, style = &quot;sd&quot;) Then, let’s overlay that layer to the zipcode boundary. tm_shape(Chi_Zipsf.3435) + tm_polygons(col = &quot;gray80&quot;) + tm_shape(housing.3435) + tm_bubbles(&quot;Units&quot;, col = &quot;purple&quot;) You can also color-code according to the total number of units. Here, we’ll add a palette using a “viridis” color scheme, as a graduate color point map. For extra style, we’ll add labels to each zip code, update with a new basemap, and make the whole map interactive. tmap_mode(&quot;view&quot;) ## tmap mode set to interactive viewing #Add Basemap tm_basemap(&quot;Esri.WorldGrayCanvas&quot;) + #Add First Layer, Style tm_shape(Chi_Zipsf.3435) + tm_borders(col = &quot;gray10&quot;) + tm_text(&quot;zip&quot;, size = 0.7) + #Add Second Layer, Style tm_shape(housing.3435) + tm_bubbles( col = &quot;Units&quot;, style = &quot;quantile&quot;, pal = &quot;viridis&quot;, size = 0.1) Example 2. COVID-19 &amp; Methadone In the first example, let create a map showing both COVID-19 and methadone clinic data (used in A.3). First, let’s add our zipcode map. With this overlay, we’ll add a “hack” to include the methadone clinic points in a legend. tmap_mode(&quot;plot&quot;) ## tmap mode set to plotting ##Add and style First Layer tm_shape(Chi_Zipsf) + tm_polygons(&quot;Case.Rate...Cumulative&quot;, style=&quot;jenks&quot;, pal=&quot;BuPu&quot;, n=4, title = &quot;COVID Rt&quot;) + ##Add Second Layer tm_shape(methadoneSf) + tm_dots(size = 0.2, col = &quot;gray20&quot;) + ##&quot;Hack&quot; a manual symbology for dots in the legend tm_add_legend(&quot;symbol&quot;, col = &quot;gray20&quot;, size = .2, labels = &quot;Methadone MOUD&quot;) + ##Final Cartographic Styling tm_layout(legend.outside = TRUE, legend.outside.position = &quot;right&quot;) Resources For tips on using tmap, check out the online text, Elegant and informative maps with tmap by Tennekes and Nowosad. Try out more mapping with the ggplot2 library. The Maps chapter will give you a head start. We highlight recommend Chapters 3-5 as mandatory reading in this classic, Geocomputation with R. Perfecting selections and filters in the Attribute Data Operations chapter will help you become a data wrangling master. Perfect distance metrics and essential GIS operations in subsequent chapters. The Appendix in Gimond’s Intro to GIS online book has a super overview of R examples, not to be missed. Another superb resource is Analyzing US Census Data by Kyle Walker, with some of our favorite examples of extracing &amp; reshaping data directly from the Census using code. Highly recommended! "]]
